---
title: "Assignment 3 Spatial Data S24"
excerpt_separator: "<!--more-->"
categories:
  - Blog
tags:
  - Assignments
  - metadata
  - chatGPT
  - S24
  - spatial
---

# Guidelines for the Assignment: 

The Spatial Data Assignment is an assignment in one step. It builds upon the work we did in class on October 17th, with a refresher on November 16th. 

This assignment can be done alone or in pairs.  

This exercise has five main elements: (1) choosing a source (2) identifying the spatial elements of any humanities source material (3) modeling a spatial dataset based on those elements, (4) enriching the spatial data with any other relevant metadata, (5) visualizing the data on a map, discussion and interpretion.

> For this exercise, if you want to semi-automate the process you will need an account at openai.com

**Step 1**: Choice of source. You should identify the sourcebook you would like to work with. Below is a list of possible sources from archive.org, but you can also find your own. **Please check with the instructor if you use one which is not included below**. 

Source #1 [The Brooklyn City and Business Directory 1879-80](https://archive.org/details/1880BPL/page/n21/mode/2up). This directory contains names of people, their professions and street addresses. The text is already available. This source will be particularly good if you are interested in the history of New York City.  

Source #2 [Radio and Television Annual year Book (1962)](https://archive.org/details/radioannual1962/mode/2up). For this source, it would make sense to pick one of the categories (advertising agencies, transcription companies, etc.)

Source #3 [Travel Guide to Chennai](https://archive.org/details/TravelGuideToChennai/mode/2up).

Source #4 [Fielding's Travel Guide to Europe](https://archive.org/details/in.ernet.dli.2015.149144/page/n1/mode/2up)

Source #5 [Standard Guide to Cuba, 1905](https://archive.org/details/standardguideto00cogoog/mode/2up)

Source #6 [Promenade dans Paris-in French](https://archive.org/details/promenadedanspar0000viei/page/n1/mode/2up). This source would require OCR. 

Source #7 [An Atlas of Ancient Egypt](https://archive.org/details/cu31924026363097/mode/2up)

Source #8 [UAE Exports & Industry Directory - 2017-18](https://archive.org/details/Directory_201704/mode/2up)

Source #9 [Smolensk Telephone Book from 1910 - in Russian Список абонентов Смоленской телефонной сети, устроенной и эксплуатируемой Правительством](https://archive.org/details/1910-smolensk-tspr-1910/mode/2up). 

If your source has not been optically character recognized (OCR'd), you need to do this. You can reach out to the instructor to help with this--it takes just a few minutes to do. 

**Step 2**: Modeling the data. You should identify what data is available from the source. 

For some sources, the number of pages involved may make it very difficult to extract all the information using chatGPT 3.5. You should make a choice of which part of the source you will work on, by which I mean, you will have to choose the number of pages you will use and you may have to work in batches. You want to have a dataset of at least 50 rows or so. This can be accomplished manually. If you use chatGPT to extract the data, please make sure that the number of rows is significantly larger than that. 

**Step 3**:  Enriching the data. Geocoding. Adding any other data. 

When you are working with the data one of the things you will want to do is to examine what kinds of other information can be associated with the main points. You will need to add on columns which achieve that. These will be different according to the source. 

Examples of other columns might be
- professions of people
- numbers of people
- gender of person
- neighborhoods, etc. 

Finally, you can geocode by hand or automate that process using Geocode by Awesome Table so that you have latitude and longitude columns. 

**Step 4**:  Visualizing the data. Discussion and Interpretation. 

Your choices for visualizing the spatial data are numerous. Perhaps the easiest is kepler.gl or google MyMaps. UMAP is fine, as are other packages. 

Use color categories for the points to categorize types of points. When you have a map that shows the extent of your data, you can screenshot it and include it as an image.

Insert the following line where you want the image to show up in the body of the .md file of your assignment:

`<img src="/assets/{filename}.png" style="zoom:50%"/>`

Use the zoom percentage to size the file. An example of the code of one of your instructor's research projects can be found [here](https://raw.githubusercontent.com/parisbible/parisbible.github.io/main/_posts/2022-10-31-bible-hunting-Italy.md)

# Guiding questions for this assignment:

- What kind of source is it? 
- What kinds of data does that source provide? 
- Was the data directly or indirectly communicated? In other words, did you have to assume anything to create new columns? 
- If you used chatGPT, how did you create a prompt to automate the extraction of the information? 
- When you mapped the data, did you see any interesting patterns? Were there areas of concentration of points? Did mapping the additional columns (profession, gender, etc) lead to any visible clusters?
- If you were to do this over many more pages then you did for this assignment, what kind of results do you think the different scale would give?
- If you were to do this assignment with a source not included here, what would your ideal source be?  


Your assignment should be about 1250 words long, with several images, embedded links. Use a markdown cheatsheet such as this [one](https://www.markdownguide.org/cheat-sheet) to stylize your post, adding different layout features and embedded links if needed. You can refer to the readings if you want to, but this is not necessary for this assignment. **Due date: 25 November**.
